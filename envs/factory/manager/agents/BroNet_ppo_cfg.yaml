seed: 42
num_envs: 256
#replicate_physics: False
#scene:
#  replicate_physics: False
# this is the parameters for the BroNet shared model
models:
  force_encoding: None
  act_init_std: 0.16 #0.25 #0.60653066
  critic:
    n: 2
    latent_size: 512
  actor:
    n: 2
    latent_size: 512

agent:
  class: PPO
  rollouts: 50 #75
  learning_epochs: 2
  mini_batches: 100 #32 # 128 steps / minibatch 128 steps / minibatch (256 envs * 50 steps per update)
  discount_factor: 0.99
  lambda: 0.99 #0.95
  learning_rate: 5.0e-5 #1.0e-04 # (optimized for PiH)

  learning_rate_scheduler: KLAdaptiveLR
  learning_rate_scheduler_kwargs:
    kl_threshold: 0.0255 #0.01
  # below are not args
  random_timesteps: 0
  learning_starts: 0
  grad_norm_clip: 1.0 # 0.5
  ratio_clip: 0.2
  clip_predicted_values: False #True
  #value_clip: 0.0 #0.2
  entropy_loss_scale: 3.0e-5 #0.000005
  value_loss_scale: 1.0 # 0.5
  kl_threshold: 0.05 #0.0
  rewards_shaper_scale: 1.0
  time_limit_bootstrap: False

  agent_is_list: False
  # logging and checkpoint
  experiment:
    directory: "Tests"
    experiment_name: "test"
    write_interval: 50 #75
    checkpoint_interval: 2000
  
  logging_tags:
    obs_type: "basic" # "basic", "policy_history", "history", "DMP"
    act_type: "basic" # "basic", "predict_action", "DMP"

video_tracking:
  # note to use this must run with --video --enable_cameras
  record_training: True
  train_video_interval: 450
  record_evals: True
  video_length: 50


defaults:
  - override hydra/job_logging: custom